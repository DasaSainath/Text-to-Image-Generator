 # Project Report

## Problem Statement
Generative AI, particularly **text-to-image** generation, allows users to create images from textual descriptions. This project uses **Stable Diffusion** to explore this concept.

## Model Overview
**Stable Diffusion** is a text-to-image model that generates high-quality images from text prompts. The model is based on **Latent Diffusion** and uses a pre-trained neural network for image generation.

## Usage
The model takes a text prompt and generates a corresponding image. The **Flask** app or **Streamlit** interface allows users to input text and receive the generated image.

## Challenges
- Model performance can be slow on CPU.
- API key usage limits on Hugging Face.
- Image generation quality can vary depending on the text prompt.

## Learnings
- Fine-tuning models can improve results for specific prompts.
- Stable Diffusion is highly effective for artistic and creative image generation.

